{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b816326-9f8f-4bc0-854a-82ed67482445",
   "metadata": {},
   "source": [
    "# LangChain(v0.3) 의 주요 Components\n",
    "https://python.langchain.com/docs/how_to/#components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0179d-7104-4b31-bfdb-137413266ffc",
   "metadata": {},
   "source": [
    "# prompts\n",
    "https://python.langchain.com/api_reference/core/prompts.html#module-langchain_core.prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe935d0-90e4-40aa-a36a-9c464b08ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "prompts class 계층도\n",
    "\n",
    "BasePromptTemplate --> PipelinePromptTemplate\n",
    "                       StringPromptTemplate --> PromptTemplate\n",
    "                                                FewShotPromptTemplate\n",
    "                                                FewShotPromptWithTemplates\n",
    "                       BaseChatPromptTemplate --> AutoGPTPrompt\n",
    "                                                  ChatPromptTemplate --> AgentScratchPadChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "BaseMessagePromptTemplate --> MessagesPlaceholder\n",
    "                              BaseStringMessagePromptTemplate --> ChatMessagePromptTemplate\n",
    "                                                                  HumanMessagePromptTemplate\n",
    "                                                                  AIMessagePromptTemplate\n",
    "                                                                  SystemMessagePromptTemplate\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc958cf-69c7-4f2c-9e1f-61975e6ca89e",
   "metadata": {},
   "source": [
    "# FewShotPromptTemplate\n",
    "- 모델에 예제(example) 주기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9120189d-3858-4be2-b515-627b8d37c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a13a54-7601-4fb1-9f46-68800a66b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a031e7-d07f-4b15-b9a0-26ec393282d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 직전에 배운 PromptTemplate\n",
    "# 방법1\n",
    "t = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "t.format(country='France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dc8f33-4fbc-42e3-b228-901cf2cb2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿을 만드는 이점 또 한가지!\n",
    "# prompt template 을 디스크에 '저장'하고 'load' 할 수 있기 떼문이다.\n",
    "\n",
    "# 나중에 LLM 다룰때 prompt 는 매우 중요합니다.\n",
    "# 대규모 프로젝트에서는 \n",
    "# - 'prompt 만 만드는 팀'이 있고\n",
    "# - '코딩하는 팀'이 따로 있을것이다.  \n",
    "#    데이터베이스나 파일 등에 만들어 저장해 놓은 prompt 를 load 해야 할겁니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0286a3-3540-4547-9826-6517f3cb7d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법2\n",
    "t2 = PromptTemplate(\n",
    "    template=\"What is the capital of {country}\",\n",
    "    input_variables=['country']  # 입력변수들을 PromptTemplate 에 알려준다\n",
    ")\n",
    "\n",
    "t2.format(country='France')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8ba9a-c130-4b35-bd21-6217fc10c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에게 '어떻게 대답해야 하는 지에 대한 예제(example)'를 AI 모델에게 주는 것이\n",
    "# prompt 를 사용해서 '어떻게 대답해야 하는지 알려주는 것'보다 훨씬 좋다\n",
    "\n",
    "# FewShotPromptTemplate 이 하는 일이 바로 그거다!\n",
    "# - 이를 통해 예제(샘플)를 형식화(포맷) 할수 있다.\n",
    "# - 이런 예제들을 데이터베이스등에 저장시켜놓고 활용할수도 있다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86dc7f3-6cf9-42a6-8117-61d4383843a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af0ad78b-f104-4d7e-a777-8d8aa36bfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↓ 이 예제들은\n",
    "# 모델이 나에게 '이런 식으로 답변해 줬으면 좋겠다' 하는 예제들입니다\n",
    "\n",
    "examples = [\n",
    "  {\n",
    "    \"question\": \"What do you know about France?\",\n",
    "\n",
    "    # ↓ 원하는 형식의 답변 이다..\n",
    "    \"answer\": \"\"\"\n",
    "      Here is what I know:\n",
    "      Capital: Paris\n",
    "      Language: French\n",
    "      Food: Wine and Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What do you know about Italy?\",\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Rome\n",
    "      Language: Italian\n",
    "      Food: Pizza and Pasta\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What do you know about Greece?\",\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Athens\n",
    "      Language: Greek\n",
    "      Food: Souvlaki and Feta Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1af34b77-263b-4c15-9951-c307e0d857bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France is a country located in Western Europe. It is known for its rich history, culture, and cuisine. The capital city is Paris, which is famous for landmarks such as the Eiffel Tower and the Louvre Museum. France is also known for its wine production, fashion industry, and art scene. The country has a diverse landscape, including mountains, beaches, and countryside. French is the official language, and the currency is the Euro. France is a member of the European Union and is one of the most visited countries in the world."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='France is a country located in Western Europe. It is known for its rich history, culture, and cuisine. The capital city is Paris, which is famous for landmarks such as the Eiffel Tower and the Louvre Museum. France is also known for its wine production, fashion industry, and art scene. The country has a diverse landscape, including mountains, beaches, and countryside. French is the official language, and the currency is the Euro. France is a member of the European Union and is one of the most visited countries in the world.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run--688b886e-d68b-4200-b147-e2d53828fcad-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 '예제(example) ' 없이 전달하면?\n",
    "chat.invoke(\"What do you know about France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25dea268-ef26-48aa-9840-f5c681b28dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FewShotPromptTemplate 을 사용하여 만들기.\n",
    "example_template = \"\"\"\n",
    "    Human: {question}\n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "# ↑ {question} 과 {answer} 는 위 샘플과 동일한 key를 사용하여 작성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02dafaa6-286b-4a13-aff2-9278d1e89568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['answer', 'question'], input_types={}, partial_variables={}, template='\\n    Human: {question}\\n    AI: {answer}\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8922f359-a75f-4307-945c-1525d4c681b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotPromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, examples=[{'question': 'What do you know about France?', 'answer': '\\n      Here is what I know:\\n      Capital: Paris\\n      Language: French\\n      Food: Wine and Cheese\\n      Currency: Euro\\n      '}, {'question': 'What do you know about Italy?', 'answer': '\\n      I know this:\\n      Capital: Rome\\n      Language: Italian\\n      Food: Pizza and Pasta\\n      Currency: Euro\\n      '}, {'question': 'What do you know about Greece?', 'answer': '\\n      I know this:\\n      Capital: Athens\\n      Language: Greek\\n      Food: Souvlaki and Feta Cheese\\n      Currency: Euro\\n      '}], example_prompt=PromptTemplate(input_variables=['answer', 'question'], input_types={}, partial_variables={}, template='\\n    Human: {question}\\n    AI: {answer}\\n'), suffix='Human: What do you know about {country}?')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt= example_prompt,   # 사용할 prompt\n",
    "    examples = examples, \n",
    "\n",
    "    # ↑ 이렇게만 해도 랭체인이 알아서 각각의 예제 리스트들을\n",
    "    #  위 prompt 를 사용하여 포맷팅(형식화) 합니다\n",
    "\n",
    "    # 여기에 유저의 질문을 넣어줄겁니다\n",
    "\n",
    "    # suffix=\n",
    "    # 형식화된 모든 예제 마지막에 나오는 내용.\n",
    "    # 그래서 한번 다 형식화가 끝난 다음, 사용자의 질문은 무엇인지 나옵니다\n",
    "\n",
    "    # 여기서는 위에 있는 동일한 형식을 사용할 겁니다  \n",
    "\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "\n",
    "    #  어떤 변수를 suffic 에서 사용할 것인지 지정해 주어야 한다\n",
    "    input_variables=['country']\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b7b930b-fdcd-41cf-be1b-5bdb896eaf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Human: What do you know about France?\n",
      "    AI: \n",
      "      Here is what I know:\n",
      "      Capital: Paris\n",
      "      Language: French\n",
      "      Food: Wine and Cheese\n",
      "      Currency: Euro\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "    Human: What do you know about Italy?\n",
      "    AI: \n",
      "      I know this:\n",
      "      Capital: Rome\n",
      "      Language: Italian\n",
      "      Food: Pizza and Pasta\n",
      "      Currency: Euro\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "    Human: What do you know about Greece?\n",
      "    AI: \n",
      "      I know this:\n",
      "      Capital: Athens\n",
      "      Language: Greek\n",
      "      Food: Souvlaki and Feta Cheese\n",
      "      Currency: Euro\n",
      "      \n",
      "\n",
      "\n",
      "Human: What do you know about Germany?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(country='Germany'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e5548-d573-4d04-b738-970688259f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1  example 리스트를 만들고   examples\n",
    "# step2  FewShotPromptTemplate 에 전달했고 examples=\n",
    "# step3  어떻게 전달한 예제들을 형식화 할지 알려주었고\n",
    "# step4  마지막에 질문을 포함시켰다.  suffix, input_variables\n",
    "\n",
    "# AI 는 우리의 예제들과 똑같은 구조, 형태로 답변하게 될겁니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df92e918-7d38-4637-9d44-a9e6dc5d001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cabe1c76-0550-4858-b6e0-807b04d202d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "      Here is what I know:\n",
      "      Capital: Berlin\n",
      "      Language: German\n",
      "      Food: Bratwurst and Sauerkraut\n",
      "      Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI: \\n      Here is what I know:\\n      Capital: Berlin\\n      Language: German\\n      Food: Bratwurst and Sauerkraut\\n      Currency: Euro', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run--66d85fdc-88ad-468c-8b8e-4ef5fbb23d24-0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"country\": \"Germany\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df24c7c9-633a-4a43-a739-3807b5caa73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "      Here is what I know:\n",
      "      Capital: Ankara\n",
      "      Language: Turkish\n",
      "      Food: Kebab and Baklava\n",
      "      Currency: Turkish Lira"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI: \\n      Here is what I know:\\n      Capital: Ankara\\n      Language: Turkish\\n      Food: Kebab and Baklava\\n      Currency: Turkish Lira', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run--4a8a6dda-8481-419f-960c-262e14c3b5cf-0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"country\": \"Turkey\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb25bcc-7460-46e6-8c3c-2feff9d40f20",
   "metadata": {},
   "source": [
    "# FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb74a96d-e242-45bc-bfe7-7ed001df92e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain_core.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "# https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html\n",
    "\n",
    "# v0.3\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "# https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd604c65-4688-4f5d-a324-499ebec69943",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  {\n",
    "    \"country\": \"France\",  # <-- 변경\n",
    "    \"answer\": \"\"\"\n",
    "      Here is what I know:\n",
    "      Capital: Paris\n",
    "      Language: French\n",
    "      Food: Wine and Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"country\": \"Italy\",  # <-- 변경\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Rome\n",
    "      Language: Italian\n",
    "      Food: Pizza and Pasta\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"country\": \"Greece\",  # <-- 변경\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Athens\n",
    "      Language: Greek\n",
    "      Food: Souvlaki and Feta Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a28d11b-2806-43a8-abf9-c6b99615f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"What do you know about {country}?\"),\n",
    "    (\"ai\", \"{answer}\"),\n",
    "])\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt, \n",
    "    examples=examples,\n",
    "    # suffix= 등은 필요없다.\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert, you give short answers.\"),\n",
    "    example_prompt,  # !!\n",
    "    (\"human\", \"What do you know about {country}?\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8007deb2-e9a2-4e61-8b7a-03574ffa0ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = final_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7e41524-a106-435d-b154-e298114d581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      I know this:\n",
      "      Capital: Berlin\n",
      "      Language: German\n",
      "      Food: Bratwurst and Sauerkraut\n",
      "      Currency: Euro\n",
      "      "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n      I know this:\\n      Capital: Berlin\\n      Language: German\\n      Food: Bratwurst and Sauerkraut\\n      Currency: Euro\\n      ', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run--d5217692-cf4d-4bbc-b206-d31da08fb53f-0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"country\": \"Germany\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "373b151c-2667-4edb-9980-133e9593fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  때로는 수천개의 예제를 가지고 있을텐데,  이를 모두 모델에게 줄수 없는 상황이 있을수 있다.\n",
    "#    이유1) 비용이 많이 든다..  많은 텍스트 땜에.\n",
    "#    이유2) '허용하는 범위' 라는게 있다 => 모~든 예제들을 모델에게 줄 수는 없다.  제한이 있다 (context window)\n",
    "\n",
    "#  그래서 예제를 선별하는 방법에 대해 배워보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3fc1ab-47c1-4444-b76f-7fffebd5a662",
   "metadata": {},
   "source": [
    "# LengthBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41cbdd4c-a5bd-414c-9195-fa735a746ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain_core.example_selectors.length_based import LengthBasedExampleSelector\n",
    "# https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.length_based.LengthBasedExampleSelector.html#langchain_core.example_selectors.length_based.LengthBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e43fe8a-263b-4941-9b0b-92b65d6f0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83ff0610-ede1-478e-8f0a-bedd4348c3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['answer', 'country'], input_types={}, partial_variables={}, template='Human: {country}\\nAI: {answer}')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = PromptTemplate.from_template(\"Human: {country}\\nAI: {answer}\")\n",
    "\n",
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4f41ee6-514e-48bf-82f9-e4575667a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example selector 생성\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt, \n",
    "    max_length=10,    # 예제의 양을 얼마나 허용할 지 정해주기. max_length 값 을 넘어가는 예제는 cut out 된다\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt= example_prompt, \n",
    "    # examples = examples, \n",
    "    example_selector=example_selector,  # <- max_length= 값에 따라 예제의 양을 정해줄 수 있다.\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=['country']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ce2dc70-c997-4265-943b-a8dd3b8ce70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about Brazil?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(country='Brazil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eadfe09-ab61-407d-a3d8-d55102792bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "'Human: What do you know about Brazil?'\n",
    "\n",
    "선택된 example 이 없다?  => max_length= 값을 변경해보자\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e98edee3-59cb-47c2-87f1-b622be538d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: France\n",
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Paris\n",
      "        Language: French\n",
      "        Food: Wine and Cheese\n",
      "        Currency: Euro\n",
      "        \n",
      "\n",
      "Human: What do you know about Brazil?\n"
     ]
    }
   ],
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt, \n",
    "    max_length=80,   # <-- 값을 변경!\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt= example_prompt, \n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "\n",
    "print(prompt.format(country='Brazil'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dffdbf50-2d13-4f57-a3ad-8b6ba062a698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: France\n",
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Paris\n",
      "        Language: French\n",
      "        Food: Wine and Cheese\n",
      "        Currency: Euro\n",
      "        \n",
      "\n",
      "Human: Italy\n",
      "AI: \n",
      "        I know this:\n",
      "        Capital: Rome\n",
      "        Language: Italian\n",
      "        Food: Pizza and Pasta\n",
      "        Currency: Euro\n",
      "        \n",
      "\n",
      "Human: What do you know about Brazil?\n"
     ]
    }
   ],
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt, \n",
    "    max_length=180,   # <-- 값을 좀더 크게 하면?\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt= example_prompt, \n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "\n",
    "print(prompt.format(country='Brazil'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d384fee4-e731-4f74-a130-1e3feeb6b793",
   "metadata": {},
   "source": [
    "## Custom ExampleSelector (BaseExampleSelector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bd22b-35f3-4108-9bfe-50f41237e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 램덤하게 exmaple 를 select 하는 ExampleSelector 를 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b20dc4c4-4de0-4579-8e57-fc12092111df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain_core.example_selectors.base import BaseExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0ebb65d-d029-4c0c-b0ad-296506b98606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseExampleSelector 의 구현객체를 만드려면\n",
    "#  상속 받은뒤 select_examples() 과 add_example() 을 반드시 오버라이딩 해주어야 한다.\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    # select_examples()\n",
    "    # 입력에 따라 어떠한 샘플을 사용할지 select 함.\n",
    "    \n",
    "    # 이번 예제에서는 examples 리스트 에서 random 으로 선택하게 하려 함.\n",
    "    # ※ 이는 얼마든지 복잡하게 만들어 볼수도 있다.\n",
    "    def select_examples(self, input_variables):    \n",
    "        from random import choice\n",
    "        return [choice(self.examples)]   # 무작위로 선택 1개 한 뒤, list에 담아 리턴.\n",
    "\n",
    "    # add_example()\n",
    "    # Add new example to store.  이미 존재하는 example 에 example 을 추가하는 method\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d8cec77e-d7c2-4f78-92a5-2f3a1e31e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Greece\n",
      "AI: \n",
      "        I know this:\n",
      "        Capital: Athens\n",
      "        Language: Greek\n",
      "        Food: Souvlaki and Feta Cheese\n",
      "        Currency: Euro\n",
      "        \n",
      "\n",
      "Human: What do you know about Brazil?\n"
     ]
    }
   ],
   "source": [
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt= example_prompt, \n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "\n",
    "print(prompt.format(country='Brazil'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ffa976-d9f4-4780-9eda-768df9678230",
   "metadata": {},
   "source": [
    "# PromptTemplate 저장 / 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb18912-2643-47b7-ab51-05f281918f0f",
   "metadata": {},
   "source": [
    "## json 파일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8de3bdd4-0ed8-4cd5-a416-eed9bc43c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt.json 파일을 생성합니다\n",
    "with open('prompt.json', 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "    {\n",
    "      \"_type\":\"prompt\",\n",
    "      \"template\":\"What is the capital of {country}\",\n",
    "      \"input_variables\":[\"country\"]\n",
    "    }\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9f7903c6-b13d-4476-b85e-3bf2eba03fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain_core.prompts.loading import load_prompt\n",
    "# https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.loading.load_prompt.html\n",
    "# Unified method for loading a prompt from LangChainHub or local fs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2a49e3ab-6e20-44de-b0fb-0a18d720c454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = load_prompt('./prompt.json')\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "81ef65d8-1c93-442c-a39f-72f9ca6f6800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Germany'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 포맷팅\n",
    "prompt.format(country='Germany')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dbcdbb-80cd-4f0f-84a5-7af58d408991",
   "metadata": {},
   "source": [
    "## yaml 파일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "225dde0f-83f4-456d-9e14-1b087daeb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompt.yaml', 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "_type: \"prompt\"\n",
    "template: \"What is the capital of {country}\"\n",
    "input_variables: [\"country\"]\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4820244b-4535-4b7f-bb49-67c7587f05c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['country'] input_types={} partial_variables={} template='What is the capital of {country}'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the capital of China'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "print(prompt)\n",
    "\n",
    "prompt.format(country='China')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b99a81b-c3ba-42eb-85f5-c580296e8e66",
   "metadata": {},
   "source": [
    "# Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec3c60-024a-4211-848d-c246e88d1afa",
   "metadata": {},
   "source": [
    "## set_llm_cache(),  InMemoryCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "66998509-0e69-41bf-81d6-a63d5cec64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain_core.globals import set_llm_cache\n",
    "# https://python.langchain.com/api_reference/core/globals/langchain_core.globals.set_llm_cache.html#set-llm-cache\n",
    "# Set a new LLM cache, overwriting the previous value, if any.\n",
    "\n",
    "# v0.3\n",
    "from langchain_core.caches import InMemoryCache\n",
    "# https://python.langchain.com/api_reference/core/caches/langchain_core.caches.InMemoryCache.html\n",
    "\n",
    "# Cache that stores things in 'memory'.\n",
    "# Initialize with empty cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d623b64d-7f63-4e41-9650-418176c42ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_llm_cache(InMemoryCache())  # <- LLM 의 모든 response 가 '메모리' 에 저장(cache) 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4f9c8f3a-81f3-4ae7-ad07-3bc0138bac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "50373ba2-dd86-4be8-88b7-36c5e5952fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 질문을 두번 해볼거다.  \n",
    "# 우선 시간 측정하는 함수도 준비해보자.\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "def check_laptime(message):\n",
    "    start_time = time.time()\n",
    "    response = chat.invoke(message)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time # 경과 시간.\n",
    "    print('▶ 경과시간 %s' % (str(timedelta(seconds = elapsed_time))))\n",
    "    print(f'{len(response.content)} 글자: {response.content}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5d3d2a7b-17ea-4f1a-8009-663321cb3199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 경과시간 0:00:04.792942\n",
      "966 글자: To make Italian pasta, you will need the following ingredients:\n",
      "\n",
      "- 2 cups of all-purpose flour\n",
      "- 2 large eggs\n",
      "- Pinch of salt\n",
      "\n",
      "Here is a step-by-step guide to making Italian pasta:\n",
      "\n",
      "1. On a clean work surface, pour the flour and create a well in the center.\n",
      "2. Crack the eggs into the well and add a pinch of salt.\n",
      "3. Using a fork, gradually mix the eggs into the flour until a dough forms.\n",
      "4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\n",
      "5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\n",
      "6. After resting, divide the dough into smaller portions and roll each portion out into a thin sheet using a pasta machine or rolling pin.\n",
      "7. Cut the rolled-out dough into desired shapes such as fettuccine, spaghetti, or ravioli.\n",
      "8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes or until al dente.\n",
      "9. Drain the pasta and toss with your favorite sauce or toppings.\n",
      "\n",
      "Enjoy your homemade Italian pasta!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_laptime(\"How do you make Italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0669ed91-c71f-464b-9118-084e8b29d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 경과시간 0:00:00\n",
      "966 글자: To make Italian pasta, you will need the following ingredients:\n",
      "\n",
      "- 2 cups of all-purpose flour\n",
      "- 2 large eggs\n",
      "- Pinch of salt\n",
      "\n",
      "Here is a step-by-step guide to making Italian pasta:\n",
      "\n",
      "1. On a clean work surface, pour the flour and create a well in the center.\n",
      "2. Crack the eggs into the well and add a pinch of salt.\n",
      "3. Using a fork, gradually mix the eggs into the flour until a dough forms.\n",
      "4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\n",
      "5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\n",
      "6. After resting, divide the dough into smaller portions and roll each portion out into a thin sheet using a pasta machine or rolling pin.\n",
      "7. Cut the rolled-out dough into desired shapes such as fettuccine, spaghetti, or ravioli.\n",
      "8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes or until al dente.\n",
      "9. Drain the pasta and toss with your favorite sauce or toppings.\n",
      "\n",
      "Enjoy your homemade Italian pasta!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_laptime(\"How do you make Italian pasta?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e8778-cb9e-4b25-93fd-a10ad6633e3f",
   "metadata": {},
   "source": [
    "## set_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a87a09f7-fe8e-40a5-87b4-5a3536a8012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain_core.globals import set_debug\n",
    "# https://python.langchain.com/api_reference/core/globals/langchain_core.globals.set_debug.html#langchain_core.globals.set_debug\n",
    "# Set a new value for the debug global setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "12e40c6b-f884-4ef5-949b-5c25fe2e2951",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "58b6d6b1-be41-4ee3-9984-9f12498f01f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make Italian pasta?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [3ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, divide the dough into smaller portions and roll each portion out into a thin sheet using a pasta machine or rolling pin.\\n7. Cut the rolled-out dough into desired shapes such as fettuccine, spaghetti, or ravioli.\\n8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 233,\n",
      "                \"prompt_tokens\": 14,\n",
      "                \"total_tokens\": 247,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"id\": \"chatcmpl-BhbQuBBQVFBpn25LunOidpCZuwF33\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--5250a6d8-0b1f-4baf-8db9-4a1597b2f346-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 14,\n",
      "              \"output_tokens\": 233,\n",
      "              \"total_tokens\": 247,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        },\n",
      "        \"text\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, divide the dough into smaller portions and roll each portion out into a thin sheet using a pasta machine or rolling pin.\\n7. Cut the rolled-out dough into desired shapes such as fettuccine, spaghetti, or ravioli.\\n8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, divide the dough into smaller portions and roll each portion out into a thin sheet using a pasta machine or rolling pin.\\n7. Cut the rolled-out dough into desired shapes such as fettuccine, spaghetti, or ravioli.\\n8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 233, 'prompt_tokens': 14, 'total_tokens': 247, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BhbQuBBQVFBpn25LunOidpCZuwF33', 'finish_reason': 'stop', 'logprobs': None}, id='run--5250a6d8-0b1f-4baf-8db9-4a1597b2f346-0', usage_metadata={'input_tokens': 14, 'output_tokens': 233, 'total_tokens': 247, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"How do you make Italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "07e931df-2ccc-40d4-aeb0-5f9487981494",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ff970-372f-45f8-b042-242898885ba5",
   "metadata": {},
   "source": [
    "## SQLiteCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cd2d4fd8-11f9-4fa5-b552-26ee6efc1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain_community.cache import SQLiteCache\n",
    "# Cache that uses SQLite as a backend.\n",
    "# Initialize by creating the engine and all tables.\n",
    "# https://python.langchain.com/api_reference/community/cache/langchain_community.cache.SQLiteCache.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c4b85bcc-6c75-419d-9245-6dba792b0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터베이스에 cache\n",
    "set_llm_cache(SQLiteCache('cache.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1e5b868b-523c-406f-8773-31b9056c127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and make a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it is smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is thin.\\n7. Cut the dough into desired shapes such as fettuccine, spaghetti, or ravioli.\\n8. Cook the pasta in a large pot of salted boiling water for 2-3 minutes or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 225, 'prompt_tokens': 14, 'total_tokens': 239, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BhbZc8z0ihiirSjGpkGf1PYkiLNfb', 'finish_reason': 'stop', 'logprobs': None}, id='run--7212f8dc-548d-445b-8331-4f3eda7e3e46-0', usage_metadata={'input_tokens': 14, 'output_tokens': 225, 'total_tokens': 239, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"How do you make Italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f948fcd3-4e8c-4c5f-8e26-5a203b50e5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and make a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it is smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is thin.\\n7. Cut the dough into desired shapes such as fettuccine, spaghetti, or ravioli.\\n8. Cook the pasta in a large pot of salted boiling water for 2-3 minutes or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 225, 'prompt_tokens': 14, 'total_tokens': 239, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BhbZc8z0ihiirSjGpkGf1PYkiLNfb', 'finish_reason': 'stop', 'logprobs': None}, id='run--7212f8dc-548d-445b-8331-4f3eda7e3e46-0', usage_metadata={'input_tokens': 14, 'output_tokens': 225, 'total_tokens': 239, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"How do you make Italian pasta?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aaf58c-1463-46d2-8129-31973f28ce7a",
   "metadata": {},
   "source": [
    "## debug, cache 끄기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3259bdbc-50f5-410d-8c89-9c3ac8ed3e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_debug(False)\n",
    "set_llm_cache(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b236b54-16a7-4dec-a099-1e789d5d3ebb",
   "metadata": {},
   "source": [
    "# Serialization\n",
    "- 모델 저장, 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a2c6e-420f-4355-9468-1ac382277edf",
   "metadata": {},
   "source": [
    "## OpenAI 모델 비용 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f8f646-c9b1-459e-b54a-b6cb079546bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.3\n",
    "from langchain_community.callbacks.manager import get_openai_callback\n",
    "# Get the OpenAI callback handler in a context manager.\n",
    "# which conveniently exposes token and cost information.\n",
    "# Returns: The OpenAI callback handler.\n",
    "# https://python.langchain.com/api_reference/community/callbacks/langchain_community.callbacks.manager.get_openai_callback.html#get-openai-callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9cae292-353d-4bef-b83c-a90c58437782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models.base import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f66619d-6154-4193-9320-b83c385be667",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b0945fe-ec70-485b-9e26-3ad6270bf32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 220\n",
      "\tPrompt Tokens: 14\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 206\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.000316\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as usage:\n",
    "    # 이 안에서 모델 호출.\n",
    "    chat.invoke(\"What is the recipe for soju\")\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b9bd590-0cf6-491c-b2b4-c82b04e1a151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💚\n",
      " Ingredients:\n",
      "- 1 cup of rice\n",
      "- 1 cup of water\n",
      "- 1 tablespoon of nuruk (fermentation starter)\n",
      "- 1 tablespoon of yeast\n",
      "\n",
      "Instructions:\n",
      "1. Rinse the rice thoroughly and soak it in water for at least 1 hour.\n",
      "2. Drain the rice and steam it until fully cooked.\n",
      "3. Let the rice cool down to room temperature.\n",
      "4. In a large bowl, mix the nuruk and yeast with water until dissolved.\n",
      "5. Add the cooked rice to the bowl and mix well.\n",
      "6. Cover the bowl with a clean cloth and let it ferment in a warm place for 3-4 days.\n",
      "7. After fermentation, strain the mixture through a cheesecloth to remove any solids.\n",
      "8. Transfer the liquid to a clean bottle and store it in a cool, dark place for at least 1 week before serving.\n",
      "\n",
      "Enjoy your homemade soju!\n",
      "💛\n",
      " Ingredients:\n",
      "- 4 cups all-purpose flour\n",
      "- 1 packet active dry yeast\n",
      "- 1 1/2 cups warm water\n",
      "- 2 tablespoons sugar\n",
      "- 2 teaspoons salt\n",
      "- 2 tablespoons olive oil\n",
      "\n",
      "Instructions:\n",
      "1. In a large mixing bowl, combine the warm water, sugar, and yeast. Let it sit for about 5-10 minutes until the yeast is foamy.\n",
      "2. Add the flour, salt, and olive oil to the yeast mixture. Mix until a dough forms.\n",
      "3. Knead the dough on a floured surface for about 5-10 minutes until it is smooth and elastic.\n",
      "4. Place the dough in a greased bowl, cover with a clean towel, and let it rise in a warm place for about 1-2 hours or until doubled in size.\n",
      "5. Punch down the dough and shape it into a loaf. Place the loaf in a greased loaf pan.\n",
      "6. Cover the loaf with a clean towel and let it rise for another 30-45 minutes.\n",
      "7. Preheat the oven to 375°F (190°C).\n",
      "8. Bake the bread for about 30-35 minutes or until golden brown and sounds hollow when tapped on the bottom.\n",
      "9. Remove the bread from the oven and let it cool before slicing and serving. Enjoy your homemade bread!\n",
      "Tokens Used: 488\n",
      "\tPrompt Tokens: 27\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 461\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0007050000000000001\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as usage:\n",
    "    # 이 안에서 모델 호출.\n",
    "    a = chat.invoke(\"What is the recipe for soju\")\n",
    "    b = chat.invoke(\"What is the recipe for bread\")\n",
    "    print('💚\\n', a.content)\n",
    "    print('💛\\n', b.content)\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "758fb9ad-bb50-4130-88e9-c6b9d80a2bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007050000000000001\n"
     ]
    }
   ],
   "source": [
    "print(usage.total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574d348b-1444-43e1-ba25-e8b27495653a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488\n"
     ]
    }
   ],
   "source": [
    "print(usage.total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19120a46-5021-4e11-8f01-7d0f6b37fc01",
   "metadata": {},
   "source": [
    "## 모델 config 를 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5c89c1-9d84-44c6-991b-15d9510bb888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 모델\n",
    "from langchain_openai.llms.base import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ef2a9f-5aa6-4563-b922-3dd1c7e12e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    temperature=0.1,\n",
    "    max_tokens=450,\n",
    "    model='gpt-4-turbo'\n",
    ")\n",
    "\n",
    "# 모델 config 를 저장\n",
    "llm.save('model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27efc1d8-4034-43d1-b978-750b9d87890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"model_name\": \"gpt-4-turbo\",\n",
      "    \"temperature\": 0.1,\n",
      "    \"top_p\": 1,\n",
      "    \"frequency_penalty\": 0,\n",
      "    \"presence_penalty\": 0,\n",
      "    \"n\": 1,\n",
      "    \"seed\": null,\n",
      "    \"logprobs\": null,\n",
      "    \"max_tokens\": 450,\n",
      "    \"_type\": \"openai\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!type model.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cee58de0-e519-487a-a93f-55a825dc4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델 (config) 를 다시 불러오기\n",
    "# v0.3\n",
    "from langchain_community.llms.loading import load_llm\n",
    "# Load LLM from a file.\n",
    "# https://python.langchain.com/api_reference/community/llms/langchain_community.llms.loading.load_llm.html#langchain_community.llms.loading.load_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffda3957-4a03-438e-9df4-b9ba263b0af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NLP2501\\NLPWork\\.venv\\Lib\\site-packages\\langchain_community\\llms\\openai.py:255: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "D:\\NLP2501\\NLPWork\\.venv\\Lib\\site-packages\\langchain_community\\llms\\openai.py:1089: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = load_llm('model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8a2d5c-1b41-4e59-ba6c-3890944c757b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIChat(client=APIRemovedInV1Proxy, model_kwargs={'model_name': 'gpt-4-turbo', 'temperature': 0.1, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'seed': None, 'logprobs': None, 'max_tokens': 450}, prefix_messages=[])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8f2ae-85a0-4e20-aead-291b4ffdd7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796543ea-3611-4c43-8e92-0de289be44c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e90d80-16d7-453b-a170-ea02746b1794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b75d14-9351-4f25-87c6-4ca39d70ae13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010e3ab-f37f-4832-9894-1002aa01b8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96478f-e132-4d7a-8c5c-657a2aff76c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c4256-b7d4-48c2-81fa-ba043a88ad00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7df305-7059-41a5-b435-5bfe5ad7d135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc04c12-09c7-4ff5-997f-d333fd8de0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c9a8c-575b-4eaf-bf43-79d75e0dacb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d072702-5785-49bc-acbc-7c213d5114d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20385322-c7bf-4ea1-bceb-db0a2dbd7012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d790560-963c-4f63-8f32-7123922d83c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3144edc-afff-4bba-848f-8efe13e0d7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc05b3-849d-4f37-ab6f-7174be31304a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f569a-a8f8-455f-930b-f45a50db92be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28597624-bd21-4483-af57-6ad4ca356aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54adf74b-0548-4db4-9fb8-138dcd03aa0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e88005-0536-4236-9be4-677a91ccb684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438c7bf-57d4-4e07-bd7a-d739fd4e78a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d9deb-9f19-41d1-9ea2-94fd5c6ede55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61146851-6603-4be3-89ad-78eba869d7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4b157b-7ffe-4954-b917-bfcb7ba02466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
