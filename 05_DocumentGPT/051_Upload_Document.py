import os
import time

print(f'âœ… {os.path.basename( __file__ )} ì‹¤í–‰ë¨ {time.strftime('%Y-%m-%d %H:%M:%S')}') # ì‹¤í–‰íŒŒì¼ëª…, í˜„ìž¬ì‹œê°„ì¶œë ¥
print(f'\tOPENAI_API_KEY={os.getenv("OPENAI_API_KEY")[:20]}...') # OPENAI_API_KEY í•„ìš”!


# v0.3
from langchain_community.document_loaders.unstructured import UnstructuredFileLoader
from langchain.embeddings.cache import CacheBackedEmbeddings
from langchain_openai.embeddings.base import OpenAIEmbeddings
from langchain.storage.file_system import LocalFileStore
from langchain_text_splitters.character import CharacterTextSplitter
from langchain_community.vectorstores.faiss import FAISS

import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ðŸ‡ file load & cache
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ì—…ë¡œë“œí•  íŒŒì¼, ìž„ë² ë”© ë²¡í„°ë¥¼ ì €ìž¥í•  ê²½ë¡œ, ë¯¸ë¦¬ ìƒì„±í•´ë‘ê¸°
upload_dir = r'./.cache/files'
embedding_dir = r'./.cache/embeddings'
if not os.path.exists(upload_dir):
    os.makedirs(upload_dir)
if not os.path.exists(embedding_dir):
    os.makedirs(embedding_dir)


def embed_file(file):
    file_content = file.read()  # ì—…ë¡œë“œí•œ íŒŒì¼ ì½ì–´ì˜¤ê¸°
    file_path = os.path.join(upload_dir, file.name)  # ì—…ë¡œë“œí•œ íŒŒì¼ì´ ì €ìž¥ë  ê²½ë¡œ
    # st.write(file_content, file_path) # í™•ì¸ìš©    

    # ì—…ë¡œë“œí•œ íŒŒì¼ ì €ìž¥
    with open(file_path, "wb") as f:
        f.write(file_content)  

    # ì—…ë¡œë“œëœ 'ê°ê°ì˜ íŒŒì¼' ë³„ë¡œ embedding cache ë””ë ‰í† ë¦¬ë¥¼ ì§€ì •í•˜ì—¬ ì¤€ë¹„
    cache_dir = LocalFileStore(os.path.join(embedding_dir, file.name))

    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        separator='\n',
        chunk_size=600,
        chunk_overlap=100,
    )

    # ì—…ë¡œë“œëœ íŒŒì¼ì„ ë¡œë“œ & split
    loader = UnstructuredFileLoader(file_path)
    docs = loader.load_and_split(text_splitter=splitter)

    # embeddings ìƒì„±í•˜ê¸° + cache í•˜ê¸°
    embeddings = OpenAIEmbeddings()
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)

    # ìœ„ embeddings ì„ vector store ì— ë„£ê¸°
    vectorstore = FAISS.from_documents(docs, cached_embeddings)

    # retriever ì–»ê¸°
    retriever = vectorstore.as_retriever()
    return retriever


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â­• Streamlit ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(
    page_title = "DocumentGPT",
    page_icon = "ðŸ“ƒ",
)

st.title("Document GPT")

st.markdown(
    """
ì•ˆë…•í•˜ì„¸ìš”!
ì´ ì±—ë´‡ì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ë¶„ì´ ì—…ë¡œë“œí•œ íŒŒì¼ì— ëŒ€í•´ AIì—ê²Œ ë¬¼ì–´ë³´ì„¸ìš”!
"""
)


file = st.file_uploader(
    label="Upload a .txt .pdf or .docx file",
    type=["pdf", "txt", "docx"],
)

if file:
    # st.write(file)  # í™•ì¸ìš©
    # â†‘ ë‚˜ì¤‘ì— ì´ íŒŒì¼ì„ UnstructuredFileLoader ì—ê²Œ íŒŒì¼ ìœ„ì¹˜ë¥¼ ë„˜ê²¨ì•¼ í•¨

    # file_content = file.read()   
    # st.write(file_content) # í™•ì¸ìš©.

    # --------------------------------------------------
    retriever = embed_file(file)


    # ---------------
    # í™•ì¸: retriever ë™ìž‘
    docs = retriever.invoke("ministry of truth") # -> List[Document]
    st.write(docs)












